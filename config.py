import os
import warnings

# ðŸ”¹ UyarÄ±larÄ± kapatma
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU; using FP32 instead")

# ðŸ”¹ Model klasÃ¶rÃ¼ ayarÄ±
# Uygulama dizini altÄ±ndaki 'WhisperModels' klasÃ¶rÃ¼nÃ¼ kullan
MODEL_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), "WhisperModels")
os.makedirs(MODEL_FOLDER, exist_ok=True)  # EÄŸer klasÃ¶r yoksa oluÅŸtur

# ðŸ”¹ Transkripsiyon klasÃ¶rÃ¼ ayarÄ±
# Proje dizinindeki 'Transkriptasyons' klasÃ¶rÃ¼nÃ¼ kullan
TRANSCRIPT_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Transkriptasyons")
os.makedirs(TRANSCRIPT_FOLDER, exist_ok=True)  # EÄŸer klasÃ¶r yoksa oluÅŸtur

# ðŸ”¹ KullanÄ±labilir modeller listesi
MODEL_LIST = [
    "tiny", "tiny.en", "base", "base.en",
    "small", "small.en", "medium", "medium.en",
    "large", "large-v2", "large-v3"
]

# ðŸ”¹ Model gereksinimleri
MODEL_REQUIREMENTS = {
    "tiny": {
        "ram": "2GB+",
        "notes": "Fast, lower accuracy",
        "size": "152MB",
    },
    "tiny.en": {
        "ram": "2GB+",
        "notes": "English-only version",
        "size": "152MB",
    },
    "base": {
        "ram": "4GB+",
        "notes": "Base model",
        "size": "292MB",
    },
    "base.en": {
        "ram": "4GB+",
        "notes": "English-only version",
        "size": "292MB",
    },
    "small": {
        "ram": "5GB+",
        "notes": "Smaller, higher accuracy",
        "size": "1GB",
    },
    "small.en": {
        "ram": "6GB+",
        "notes": "English-only version",
        "size": "1GB",
    },
    "medium": {
        "ram": "8GB+",
        "notes": "Medium model",
        "size": "2.9GB",
    },
    "medium.en": {
        "ram": "8GB+",
        "notes": "English-only version",
        "size": "2.9GB",
    },
    "large": {
        "ram": "12GB+",
        "notes": "Large model",
        "size": "5.8GB",
    },
    "large-v2": {
        "ram": "15GB+",
        "notes": "Latest large model",
        "size": "5.8GB",
    },
    "large-v3": {
        "ram": "16GB+",
        "notes": "Newest large model",
        "size": "6.2GB"
    }
}

# ðŸ”¹ Eksik modÃ¼lleri kontrol et
missing_modules = set()
for module in ["whisper", "torch", "psutil", "GPUtil"]:
    try:
        __import__(module)
    except ImportError:
        missing_modules.add(module)

